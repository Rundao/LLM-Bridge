# LLM Bridge

[English](../README.md) | [ç®€ä½“ä¸­æ–‡](README-zh-CN.md)

LLM Bridge æ˜¯ä¸€ä¸ªé›†ä¸­å¼çš„å¤§è¯­è¨€æ¨¡å‹ API ç®¡ç†å’Œè½¬å‘æœåŠ¡ã€‚å®ƒæ”¯æŒå¤šä¸ªæä¾›å•†ï¼Œå¹¶æä¾›ç»Ÿä¸€çš„ API æ¥å£ï¼Œç®€åŒ–äº†ä½¿ç”¨å’Œå¼€å‘å„ç§æ¨¡å‹çš„è¿‡ç¨‹ã€‚

## ç‰¹æ€§

- ğŸš€ ç»Ÿä¸€çš„ API æ¥å£ï¼Œå…¼å®¹ OpenAI æ ¼å¼
- ğŸ”„ æ”¯æŒæµå¼å“åº”ï¼ˆSSEï¼‰å’Œ WebSocket è¿æ¥
- ğŸ›  æ”¯æŒå¤šä¸ªä¸»æµå¤§è¯­è¨€æ¨¡å‹æä¾›å•†ï¼š
  - OpenAI
  - Google Gemini
  - Deepseek
  - å…¶ä»–å…¼å®¹ OpenAI æ ¼å¼çš„æä¾›å•†
- ğŸ”Œ çµæ´»çš„ä»£ç†é…ç½®
- ğŸ“ ç»“æ„åŒ– JSON æ—¥å¿—è®°å½•
- ğŸ”‘ API å¯†é’¥ç®¡ç†å’Œè®¤è¯
- ğŸ“Š Token è®¡æ•°å’Œä½¿ç”¨ç»Ÿè®¡

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- pip

### å®‰è£…æ­¥éª¤

1. å…‹éš†ä»“åº“ï¼š
   ```bash
   git clone https://github.com/Rundao/LLM-Bridge.git
   cd llm-bridge
   ```

2. å®‰è£…ä¾èµ–

   ï¼ˆå¯é€‰ï¼‰åˆ›å»º conda è™šæ‹Ÿç¯å¢ƒï¼š
   ```bash
   conda create -n llm-bridge python=3.12
   conda activate llm-bridge
   ```
   å®‰è£…ä¾èµ–ï¼š
   ```bash
   pip install -r requirements.txt
   ```

3. é…ç½®ç¯å¢ƒå˜é‡
   ```bash
   cp .env.example .env
   ```
   ç„¶åç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥å¿…è¦çš„é…ç½®ï¼š
   ```
   ACCESS_API_KEYS=your-access-key-1,your-access-key-2
   CLOSEAI_API_KEY=your-closeai-key
   GEMINI_API_KEY=your-gemini-key
   DEEPSEEK_API_KEY=your-deepseek-key
   ```
   å…¶ä¸­ï¼Œ`ACCESS_API_KEYS` ç”¨äºéªŒè¯ API è¯·æ±‚ã€‚
   å…¶ä»–å¯†é’¥å¯¹åº”å„ä¸ªæä¾›å•†çš„ API å¯†é’¥ã€‚

4. å¯åŠ¨æœåŠ¡
   ```bash
   cd src && uvicorn main:app --reload --port 1219
   ```
   æœåŠ¡å°†åœ¨ http://localhost:1219 ä¸Šå¯ç”¨ã€‚

## API ä½¿ç”¨

### èŠå¤©è¡¥å…¨æ¥å£

ä½¿ç”¨ curl çš„ç¤ºä¾‹ï¼š
```bash
curl http://localhost:1219/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-access-key" \
  -d '{
    "model": "closeai/gpt-4o-mini",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": true
  }'
```

ä½¿ç”¨ [Cherry Studio](https://cherry-ai.com/) çš„ç¤ºä¾‹ï¼š
- ç‚¹å‡»å·¦ä¸‹è§’çš„"è®¾ç½®"
- åœ¨"æ¨¡å‹æä¾›å•†"ä¸­ï¼Œç‚¹å‡»"æ·»åŠ "å¹¶é€‰æ‹©"OpenAI"ç±»å‹
- åœ¨"API å¯†é’¥"å­—æ®µä¸­è¾“å…¥ä½ çš„ `ACCESS_API_KEYS` ä¹‹ä¸€
- åœ¨"API URL"å­—æ®µä¸­è¾“å…¥ `http://127.0.0.1:1219`
    - æŸäº›è½¯ä»¶ï¼ˆå¦‚ [Cherry Studio](https://cherry-ai.com/)ï¼‰ä¼šè‡ªåŠ¨è¡¥å…… `/v1/chat/completions`ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
- ç‚¹å‡»"ç®¡ç†"æ·»åŠ æ¨¡å‹
- æ£€æŸ¥è¿æ¥å¹¶å¼€å§‹ä½¿ç”¨

### WebSocket æ¥å£

è¿æ¥åˆ° `/v1/ws` WebSocket ç«¯ç‚¹ä»¥è¿›è¡Œå®æ—¶åŒå‘é€šä¿¡ï¼š

```javascript
const ws = new WebSocket('ws://localhost:1219/v1/ws');

ws.onmessage = function(event) {
    console.log('æ”¶åˆ°æ¶ˆæ¯:', event.data);
};

ws.send(JSON.stringify({
    type: 'chat',
    api_key: 'your-access-key',
    payload: {
        model: 'closeai/gpt-4o-mini',
        messages: [{role: 'user', content: 'ä½ å¥½'}]
    }
}));
```

### æ”¯æŒçš„æ¨¡å‹

é€šè¿‡å‰ç¼€æŒ‡å®šæä¾›å•†ã€‚ä¾‹å¦‚ï¼š
- CloseAI æ¨¡å‹ï¼š`closeai/gpt-4o`ï¼Œ`closeai/gpt-4o-mini`
- Gemini æ¨¡å‹ï¼š`gemini/gemini-2.0-pro-exp-02-05`
- Deepseek æ¨¡å‹ï¼š`deepseek/deepseek-chat`

ä½ å¯ä»¥ä½¿ç”¨ `/v1/models` æ¥å£è·å–å®Œæ•´çš„æ”¯æŒæ¨¡å‹åˆ—è¡¨ã€‚

## è¯·æ±‚æµç¨‹

```mermaid
sequenceDiagram
    participant Client as å®¢æˆ·ç«¯
    participant Gateway as ç½‘å…³å±‚
    participant Auth as é‰´æƒ
    participant Router as è·¯ç”±
    participant Adapter as æ¨¡å‹é€‚é…å™¨
    participant LLM as å¤§æ¨¡å‹API

    Client->>Gateway: å‘é€å¯¹è¯è¯·æ±‚
    Gateway->>Auth: æ ¡éªŒAPI Key
    Auth-->>Gateway: è¿”å›ç”¨æˆ·æƒé™
    Gateway->>Router: ä¼ é€’è¯·æ±‚ä¸Šä¸‹æ–‡
    Router->>Router: æ ¹æ®ç­–ç•¥é€‰æ‹©æ¨¡å‹
    Router->>Adapter: è°ƒç”¨å¯¹åº”æ¨¡å‹é€‚é…å™¨
    Adapter->>Adapter: æ ‡å‡†åŒ–è¯·æ±‚æ ¼å¼
    Adapter->>LLM: å¼‚æ­¥è°ƒç”¨æ¨¡å‹API
    LLM-->>Adapter: è¿”å›åŸå§‹å“åº”
    Adapter->>Adapter: æ ‡å‡†åŒ–é”™è¯¯å¤„ç†
    Adapter-->>Router: è¿”å›ç»Ÿä¸€æ ¼å¼
    Router-->>Gateway: å›ä¼ å¤„ç†ç»“æœ
    Gateway->>Gateway: è®°å½•å®¡è®¡æ—¥å¿—
    Gateway-->>Client: è¿”å›æœ€ç»ˆå“åº”
```

## é¡¹ç›®ç»“æ„

```
llm-bridge/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml       # å…¨å±€é…ç½®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/ 
â”‚   â”‚   â”œâ”€â”€ gateway/      # åŸºäºFastAPIçš„è¯·æ±‚å¤„ç†å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ http_handler.py    # REST APIå¤„ç†å™¨
â”‚   â”‚   â”‚   â””â”€â”€ websocket_handler.py
â”‚   â”‚   â””â”€â”€ router.py     # è¯·æ±‚è·¯ç”±
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ base.py       # æŠ½è±¡åŸºç±»
â”‚   â”‚   â”œâ”€â”€ openai.py     # OpenAIæ ¼å¼é€‚é…å™¨
â”‚   â”‚   â””â”€â”€ gemini.py     # Gemini APIé€‚é…å™¨
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ config.py     # é…ç½®ç®¡ç†
â”‚   â”‚   â””â”€â”€ logging.py    # ç»“æ„åŒ–æ—¥å¿—
â”‚   â””â”€â”€ main.py           # æœåŠ¡å…¥å£
â”œâ”€â”€ docs/                 # æ–‡æ¡£
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®

åœ¨ `configs/config.yaml` ä¸­é…ç½®æ”¯æŒçš„æ¨¡å‹åŠå…¶è®¾ç½®ï¼š
```yaml
providers:
  closeai:
    base_url: "https://api.openai-proxy.org/v1/chat/completions"
    requires_proxy: false
    models:
      gpt-4o:
        max_tokens: 8192
        timeout: 120
      gpt-4o-mini:
        max_tokens: 4096
        timeout: 60
```

### æ—¥å¿—é…ç½®

åœ¨ `configs/config.yaml` ä¸­é…ç½®æ—¥å¿—è®¾ç½®ï¼š
```yaml
logging:
  format: "json"  # json æˆ– text
  output:
    file:
      path: "logs/llm-bridge.log"
      max_size: 10485760  # 10MB
      backup_count: 5
    console: true
  level: "info"  # debug, info, warning, error
```

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„æä¾›å•†

1. åœ¨ `src/adapters/` ä¸­åˆ›å»ºå®ç° `ModelAdapter` æ¥å£çš„æ–°é€‚é…å™¨
2. åœ¨ `configs/config.yaml` ä¸­æ·»åŠ æä¾›å•†é…ç½®
3. æ›´æ–° Router ç±»ä»¥æ”¯æŒæ–°é€‚é…å™¨
4. åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ ç›¸åº”çš„ API å¯†é’¥

### é”™è¯¯å¤„ç†

æœåŠ¡æä¾›æ ‡å‡†åŒ–çš„é”™è¯¯å¤„ç†ï¼š
- 400ï¼šè¯·æ±‚é”™è¯¯ï¼ˆæ— æ•ˆå‚æ•°ï¼‰
- 401ï¼šæœªæˆæƒï¼ˆæ— æ•ˆçš„ API å¯†é’¥ï¼‰
- 429ï¼šè¯·æ±‚è¿‡å¤šï¼ˆè¶…å‡ºé€Ÿç‡é™åˆ¶ï¼‰
- 500ï¼šå†…éƒ¨æœåŠ¡å™¨é”™è¯¯

## è®¸å¯è¯

MIT è®¸å¯è¯

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æäº¤ issues å’Œ pull requests æ¥å¸®åŠ©æ”¹è¿›é¡¹ç›®ã€‚
